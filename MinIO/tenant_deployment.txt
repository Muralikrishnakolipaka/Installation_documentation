Here is the detailed document with all the commands and steps for setting up Kubernetes, including resetting the cluster and troubleshooting. I will provide this in a Word document format.

---

### Kubernetes Setup

#### Step 1: Set Hostname and Update Hosts File
Login or ssh into each machine and run the following `hostnamectl` commands to set their respective hostnames:

```sh
sudo hostnamectl set-hostname "k8s-master01" && exec bash
sudo hostnamectl set-hostname "k8s-worker01" && exec bash
sudo hostnamectl set-hostname "k8s-worker02" && exec bash
```

Add the following entries in `/etc/hosts` file on each node:

```
132.226.153.13   k8s-master01
141.148.183.144  k8s-worker01
129.153.81.0     k8s-worker02
```

#### Step 2: Disable Swap Space on Each Node
For kubelet to work smoothly, we must disable swap space on all the nodes. Run the following commands:

```sh
sudo swapoff -a
sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
```

#### Step 3: Adjust SELinux and Firewall Rules for Kubernetes
Set SELinux mode as permissive on all the nodes using the following commands:

```sh
sudo setenforce 0
sudo sed -i --follow-symlinks 's/SELINUX=enforcing/SELINUX=permissive/g' /etc/sysconfig/selinux
```

On the master node, allow the following ports in the firewall:

```sh
sudo firewall-cmd --permanent --add-port={6443,2379,2380,10250,10251,10252,10257,10259,179}/tcp
sudo firewall-cmd --permanent --add-port=4789/udp
sudo firewall-cmd --reload
```

On the worker nodes, allow the following ports in the firewall:

```sh
sudo firewall-cmd --permanent --add-port={179,10250,30000-32767}/tcp
sudo firewall-cmd --permanent --add-port=4789/udp
sudo firewall-cmd --reload
```

#### Step 4: Add Kernel Modules and Parameters
For the Kubernetes cluster, we must add the overlay and br_netfilter kernel modules on all the nodes. Create a file and add the following content to it:

```sh
sudo tee /etc/modules-load.d/containerd.conf <<EOF
overlay
br_netfilter
EOF
```

To load the above modules, run:

```sh
sudo modprobe overlay
sudo modprobe br_netfilter
```

Next, add the following kernel parameters. Create a file with the following content:

```sh
sudo vi /etc/sysctl.d/k8s.conf
```

Add the following lines:

```
net.bridge.bridge-nf-call-iptables  = 1
net.ipv4.ip_forward                 = 1
net.bridge.bridge-nf-call-ip6tables = 1
```

Save and close the file. Now, add these parameters by running the following command:

```sh
sudo sysctl --system
```

#### Step 5: Install Containerd Runtime
Kubernetes requires a container runtime, and one of the most popular choices is containerd. Since it is not available in the default package repositories of Rocky Linux or AlmaLinux, add the following Docker repo on all the nodes:

```sh
sudo dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
```

Now, run the following dnf command to install containerd on all the nodes:

```sh
sudo dnf install containerd.io -y
```

Configure containerd to use the systemd cgroup. Execute the following commands on each node:

```sh
containerd config default | sudo tee /etc/containerd/config.toml >/dev/null 2>&1
sudo sed -i 's/SystemdCgroup \= false/SystemdCgroup \= true/g' /etc/containerd/config.toml
```

Restart and enable the containerd service using the following commands:

```sh
sudo systemctl restart containerd
sudo systemctl enable containerd
```

Verify the containerd service status by running:

```sh
sudo systemctl status containerd
```

#### Step 6: Install Kubernetes Tools
Kubernetes tools like kubeadm, kubectl, and kubelet are not available in the default package repositories of Rocky Linux 9 or AlmaLinux 9. So, to install these tools, add the following repository on all the nodes:

```sh
cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v1.28/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v1.28/rpm/repodata/repomd.xml.key
exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni
EOF
```

Next, install Kubernetes tools by running the following dnf command:

```sh
sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
```

After installing Kubernetes tools, start the kubelet service on each node:

```sh
sudo systemctl enable --now kubelet
```

#### Step 7: Install Kubernetes Cluster on Rocky Linux 9 / Alma Linux 9
Run the following kubeadm command to initialize the Kubernetes cluster from the master node:

```sh
sudo kubeadm init --control-plane-endpoint=k8s-master01 --pod-network-cidr=10.10.0.0/16
```

From the output above, make a note of the command which will be executed on the worker nodes to join the Kubernetes cluster.

To start interacting with the Kubernetes cluster, run the following commands on the master node:

```sh
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

Now, head back to the master node and run the following kubectl command to verify the nodes' status:

```sh
kubectl get nodes
```

Join the worker nodes to the cluster by running the command output by `kubeadm init` on each worker node:

```sh
kubeadm join <master-node-ip>:6443 --token <token> --discovery-token-ca-cert-hash sha256:<hash>
```

Ensure all nodes are in the Ready state:

```sh
kubectl get nodes
```

#### Step 8: Install Calico Network Addon
Calico network addon is required on the Kubernetes cluster to enable communication between pods, to make DNS service function within the cluster, and to make the nodes' status Ready. Run the following kubectl commands from the master node only:

```sh
kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/calico.yaml
```

#### Step 9: Install Helm
Install Helm:

```sh
curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
```

Add MinIO Operator Helm repository:

```sh
helm repo add minio-operator https://operator.min.io/
helm repo update
```

#### Step 10: Install MinIO Operator
Install MinIO Operator using Helm:

```sh
helm install \
  --namespace minio-operator \
  --create-namespace \
  minio-operator minio-operator/operator
```

#### Step 11: Verify MinIO Operator Installation
Check the status of the MinIO Operator pods:

```sh
kubectl get pods -n minio-operator
```

#### Step 12: Install Metrics Server (Optional)
Apply the Metrics Server manifest:

```sh
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

#### Step 13: Set Up StorageClass for PVCs
Create a StorageClass YAML file (e.g., `storageclass.yaml`):

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: standard
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
```

Apply the StorageClass:

```sh
kubectl apply -f storageclass.yaml
```

#### Step 14: Deploy MinIO Tenant
Create a Tenant YAML file (e.g., `minio-tenant.yaml`):

```yaml
apiVersion: minio.min.io/v2
kind: Tenant
metadata:
  name: minio-tenant
  namespace: minio-operator
spec:
  credsSecret:
    name: minio-creds-secret
  pools:
    - servers: 4
      volumesPerServer: 1
      volumeClaimTemplate:
        metadata:
          name: data
        spec:
          accessModes: [ "ReadWriteOnce" ]
          resources:
            requests:
              storage: 10Gi
          storageClassName: standard
  mountPath: /export
  requestAutoCert: true
```

mkdir /export

Create the secret for MinIO credentials:

```sh
kubectl create secret generic minio-creds-secret --from-literal=accesskey=minio --from-literal=secretkey=minio123 --namespace minio-operator
```

Apply the Tenant YAML file:

```sh
kubectl apply -f minio-tenant.yaml
```

#### Step 15: Verify

 MinIO Tenant Deployment
Check the status of the MinIO Tenant pods:

```sh
kubectl get pods -n minio-operator
```

#### Troubleshooting
If PVCs are still in Pending state:

1. **Check the status of PVCs:**

   ```sh
   kubectl get pvc -n minio-operator
   ```

2. **Check for any events or errors:**

   ```sh
   kubectl describe pvc <pvc-name> -n minio-operator
   ```

3. **Ensure that PersistentVolumes are created and bound:**

   ```sh
   kubectl get pv
   ```

4. **Create PersistentVolumes if necessary:**

   ```yaml
   sudo vi pv-data0.yaml

   apiVersion: v1
   kind: PersistentVolume
   metadata:
     name: pv-data0
   spec:
     capacity:
       storage: 10Gi
     accessModes:
       - ReadWriteOnce
     persistentVolumeReclaimPolicy: Retain
     storageClassName: standard
     hostPath:
       path: /mnt/data0
   ```

   ```yaml
   sudo vi pv-data1.yaml

   apiVersion: v1
   kind: PersistentVolume
   metadata:
     name: pv-data1
   spec:
     capacity:
       storage: 10Gi
     accessModes:
       - ReadWriteOnce
     persistentVolumeReclaimPolicy: Retain
     storageClassName: standard
     hostPath:
       path: /mnt/data1
   ```

   ```yaml
   sudo vi pv-data2.yaml

   apiVersion: v1
   kind: PersistentVolume
   metadata:
     name: pv-data2
   spec:
     capacity:
       storage: 10Gi
     accessModes:
       - ReadWriteOnce
     persistentVolumeReclaimPolicy: Retain
     storageClassName: standard
     hostPath:
       path: /mnt/data2
   ```

   ```yaml
   sudo vi pv-data3.yaml

   apiVersion: v1
   kind: PersistentVolume
   metadata:
     name: pv-data3
   spec:
     capacity:
       storage: 10Gi
     accessModes:
       - ReadWriteOnce
     persistentVolumeReclaimPolicy: Retain
     storageClassName: standard
     hostPath:
       path: /mnt/data3
   ```

Apply the PV YAML files:

```sh
kubectl apply -f pv-data0.yaml
kubectl apply -f pv-data1.yaml
kubectl apply -f pv-data2.yaml
kubectl apply -f pv-data3.yaml
```



To enable NodePort access for the MinIO Operator Console, you'll need to edit the service configuration. Here are the steps:
 
1. **Edit the Console Service**:
   Open the editor for the console service:

   ```sh
   kubectl edit service console -n minio-operator
   ```
 
2. **Modify the Service Configuration**:
   Change the service type to `NodePort` and specify the `nodePort` for the HTTP port.
 
   Update the `spec` section of the service to look like this:
   ```yaml
   spec:
     ports:
     - name: http
       port: 9090
       protocol: TCP
       targetPort: 9090
       nodePort: 30090 # Add this line
     - name: https
       port: 9443
       protocol: TCP
       targetPort: 9443
     selector:
       app.kubernetes.io/instance: minio-operator-console
       app.kubernetes.io/name: operator
     sessionAffinity: None
     type: NodePort # Change this line
   ```
 
3. **Save and Exit**:
   Save the changes and exit the editor. This will apply the new configuration.
 
4. **Verify the Service**:
   ```sh
   kubectl get service console -n minio-operator
   ```
 
5. **Retrieve the Console Access Token**:
   Use the following command to retrieve the JWT for logging into the MinIO Operator Console:
   ```sh
   kubectl get secret/console-sa-secret -n minio-operator -o json | jq -r ".data.token" | base64 -d
   ```
 
6. **Access the MinIO Operator Console**:
   Open your browser and go to `http://<worker-node-ip>:30090`, where `<worker-node-ip>` is the IP address of any worker node in your Kubernetes cluster.
 

### Reset Kubernetes Cluster

#### Step 1: Reset Kubernetes Cluster
Reset kubeadm on all nodes:

```sh
sudo kubeadm reset -f
sudo rm -rf /etc/cni/net.d
sudo iptables -F
sudo iptables -t nat -F
sudo iptables -t mangle -F
sudo iptables -X
```

#### Step 2: Reinitialize the Master Node
Run the following command to reinitialize the master node:

```sh
sudo kubeadm init --control-plane-endpoint=k8s-master01 --pod-network-cidr=10.10.0.0/16
```

#### Step 3: Rejoin Worker Nodes
Run the join command output by `kubeadm init` on each worker node to rejoin them to the cluster:

```sh
kubeadm join <master-node-ip>:6443 --token <token> --discovery-token-ca-cert-hash sha256:<hash>
```

### Troubleshooting Commands

#### Step 1: Verify API Server Status
Verify the status of the API server pod:

```sh
kubectl get pods -n kube-system | grep kube-apiserver
kubectl describe pod <kube-apiserver-pod-name> -n kube-system
kubectl logs <kube-apiserver-pod-name> -n kube-system
```

#### Step 2: Verify Kubelet Configuration
Ensure the kubelet is using the correct configuration:

```sh
sudo vi /var/lib/kubelet/config.yaml
```

Ensure the kubelet service configuration is correct:

```sh
sudo vi /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
```

Reload the systemd daemon and restart kubelet:

```sh
sudo systemctl daemon-reload
sudo systemctl restart kubelet
```

#### Step 3: Check Kubernetes Certificates
Ensure the Kubernetes certificates are valid and correctly configured:

```sh
ls /etc/kubernetes/pki/
openssl x509 -in /etc/kubernetes/pki/apiserver.crt -noout -dates
```

#### Step 4: Check Network Connectivity
Ensure there is network connectivity to the API server:

```sh
curl -k https://10.0.0.129:6443
```

#### Step 5: Verify Control Plane Components
Verify the status of all control plane components:

```sh
kubectl get pods -n kube-system
```
